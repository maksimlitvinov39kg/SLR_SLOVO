### Описание файлов проекта

**Основные файлы:**
1. `app.py` - Основной скрипт Streamlit-приложения:
   - Интерфейс для загрузки видео или использования веб-камеры
   - Обработка видео в реальном времени
   - Визуализация результатов распознавания
   - Интеграция всех компонентов системы

2. `model.py` - Реализация нейронной сети:
   - Класс `SOTASignLanguageModel` для распознавания жестов
   - Архитектура модели на основе PyTorch
   - Механизмы обработки пространственно-временных данных
   - Интеграция нормализации входных данных

3. `preprocessor.py` - Модуль предобработки данных:
   - Класс `PreprocessLayerBothHands` для подготовки ключевых точек
   - Фильтрация и выбор значимых landmarks
   - Нормализация и преобразование координат
   - Подготовка тензоров для модели

**Вспомогательные файлы:**
1. `sign_language_model_mappings.pkl` - Словари соответствий:
   - Преобразование между текстовыми метками жестов и числовыми ID
   - `sign2ord`: текст → ID
   - `ord2sign`: ID → текст
   - `class_names`: список распознаваемых жестов

2. `statistics.json` - Статистические данные:
   - Средние значения и стандартные отклонения координат
   - Раздельные статистики для губ, рук и позы
   - Используются для нормализации входных данных

**Структура проекта:**
```
service/
├── app.py            # Основное приложение
├── model.py          # Модель нейронной сети
├── preprocessor.py   # Обработка ключевых точек
├── sign_language_model_mappings.pkl  # Соответствия жестов
└── statistics.json   # Статистики для нормализации
```

**Ключевые особенности:**
- Поддержка двух режимов: видеофайлы и веб-камера
- Автоматическая обработка 3-секундных жестов
- Визуализация топ-5 предсказаний с уверенностью
- Оптимизированная обработка видео в реальном времени
- Интеграция MediaPipe для извлечения ключевых точек
- Адаптивная нормализация данных на основе статистик