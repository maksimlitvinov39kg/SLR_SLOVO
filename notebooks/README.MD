# Sign Language Recognition с Transformer архитектурой

## О проекте

Этот проект занимается распознаванием жестового языка, используя современные нейронные сети на основе Transformer. Модель анализирует видео и извлекает ключевые точки с лица (губы), рук (левая и правая) и тела, чтобы понять, какой жест показывается.


### Основные фишки

- **Advanced Embedding**: Каждый тип ключевых точек обрабатывается по-своему
- **Hierarchical Transformer**: Сначала анализируем короткие моменты, потом смотрим на всю последовательность целиком
- **Rotary Position Embedding (RoPE)**: Более продвинутый способ сказать модели, где что находится во времени
- **Multi-Scale Pooling**: Собираем информацию с разных временных масштабов
- **Cross-Modal Attention**: Учим модель понимать, как разные части тела связаны между собой

### Технические улучшения

1. **SwiGLU activation**: Используем более современную функцию активации
2. **RMSNorm**: Нормализация, которая помогает стабильнее обучаться
3. **Focal Loss с Label Smoothing**: Помогает справиться с тем, что некоторые жесты встречаются чаще других
4. **Адаптивные residual connections**: Модель сама учится, насколько важны пропускные соединения
5. **Auxiliary Classifiers**: Дополнительные "выходы" модели для лучшего обучения

## Как устроены данные

Модель работает с такими данными:
- **Губы**: 40 точек
- **Левая рука**: 21 точка  
- **Правая рука**: 21 точка
- **Поза тела**: 5 точек

Каждая точка - это просто координаты (x, y).

## Предобработка

Перед тем как подать данные в модель, мы:
- Убираем кадры, где руки не видны
- Нормализуем все координаты
- Приводим все видео к одной длине
- Если видео короткое - дублируем кадры, если длинное - сжимаем

## Архитектура

### 1. Embedding слой
Берет сырые координаты и превращает их в понятные модели представления. Каждый тип точек (губы, руки, тело) обрабатывается отдельно, но потом они атендятся друг с другом через cross-modal attention.

### 2. Transformer backbone
Состоит из двух частей:
- **Локальные блоки**: Ищут паттерны в коротких отрезках времени
- **Temporal Convolution**: Дополнительно помогает находить движения
- **Глобальные блоки**: Понимают связи на больших временных промежутках

### 3. Pooling слой (MultiScalePooling)
Это очень важная часть - она берет всю временную последовательность после transformer'а и "сжимает" ее в один вектор для классификации. Но делает это умно, сразу несколькими способами:
Базовые методы, такие как Average pooling и Max pooling


Многомасштабное adaptive pooling:
Тут самое интересное - мы смотрим на видео с разной "детализацией":

Масштаб 1: Всё видео как один кусок (глобальный контекст)
Масштаб 2: Делим видео пополам - начало и конец жеста
Масштаб 4: 4 части - улавливаем основные фазы движения
Масштаб 8: 8 частей - детальная временная структура

Каждый масштаб дает свой вектор признаков, потом мы их все склеиваем.

Attention-based pooling:
Самый продвинутый метод - модель сама учится, какие моменты времени самые важные для каждого конкретного жеста. Например, для жеста "привет" важнее движение руки, а для "да/нет" - движение головы.
В итоге получается богатое представление, которое учитывает и общую картину, и детали, и важность разных моментов.

### 4. Классификатор
Финальная часть, которая выдает ответ. Использует информацию с разных уровней модели и имеет несколько "промежуточных" выходов для лучшего обучения.

## Обучение

### Функция потерь
- **Focal Loss**: Помогает модели лучше учиться на редких жестах
- **Label Smoothing**
- **Auxiliary Loss**: Дополнительные потери с промежуточных слоев

### Оптимизация
- **CyclicLR с Warmup**: Как увелечние так и уменьшение lr-a во время трейна
- **MixUp**: Смешиваем примеры между собой для лучшей генерализации

### Аугментация данных
- **Time Warping**: Замедляем/ускоряем жесты
- **Gaussian Noise**: Добавляем шум к координатам (имитируем ошибки детекции кейпоинтов)
- **Scaling**: Увеличиваем/уменьшаем размер жеста

## Результаты обучения

Эксперименты проводились на NVIDIA Tesla P100 16GB с batch_size = 32. Обучение проходило в несколько этапов:

### 500 классов  

| Этап | Время | Эпохи | Проблемы |
|------|-------|-------|----------|
| Начальное обучение | 4h 46m | 169 | - |
| Дообучение 1 | 3h 29m | 123 | Early stopping |
| Дообучение 2 | 6h 25m | 228 | Переобучение с ~20 эпохи |

**Итого**: ~10h 40m, 520 эпох, 7500/2500 train/test

[Веса модели на 500 классов](https://drive.google.com/drive/u/1/folders/1HGNPHFkiVqxaSvYAxLQittpyBZiwuGcU)

### 1000 классов  

| Этап | Время | Эпохи | Проблемы |
|------|-------|-------|----------|
| Начальное обучение | 7h 18m | 100 | - |
| Дообучение 1 | 9h 27m | 130 | - |
| Дообучение 2 | 10h 57m | 150 | Переобучение с ~75 эпохи |

**Итого**: ~27h 50m, 380 эпох, 15015/5005 train/test

[Веса модели на 1000 классов](https://drive.google.com/drive/folders/1DOi0FKmL1eWTkNj8EFcTaJQ58k1kREjx)

## Что можно улучшить

### Аугментация данных
1. **Пространственные преобразования**:
   - Coordinate dropout (случайно "скрываем" некоторые точки)
   - Локальные искажения координат
   - Зеркальное отражение (меняем местами левую и правую руку)

2. **Временные преобразования**:
   - Random temporal cropping (берем случайные куски видео)
   - Нелинейное изменение скорости

3. **Физически корректные изменения**:
   - 3D вращения всего "скелета"
   - Имитация разных углов камеры
   - Реалистичный шум (как будто детектор ошибся)

### Оптимизация обучения
1. **Лучшие scheduler'ы**:
   - CosineAnnealingWithWarmRestarts
   - OneCycleLR с разными параметрами для разных слоев
   - ReduceLROnPlateau

2. **Регуляризация**:
   - Stochastic Depth (случайно "выключаем" слои)
   - LayerDrop для transformer блоков
   - Более сильный weight decay

3. **Функции потерь**:
   - Curriculum Focal Loss (постепенно усложняем задачу)
   - Pairwise margin loss для похожих классов
   - Self-distillation

### Архитектурные изменения
1. **Attention механизмы**:
   - Local window attention
   - Sparse attention patterns

2. **Мультимодальность**:
   - Cross-modal consistency loss

Основная проблема сейчас - модель начинает переобучаться на этапах дообучения. Метрики на train растут крайне быстрее чем на тесте, при этом происходит расхождение лосса